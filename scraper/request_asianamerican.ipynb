{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Progress Report:\n",
    "- DONE: Feb 14: can output a file written with comments but error in delimiters, every character delimited by ','\n",
    "    Also, Python error about being unable to transcribe unicode for a certain string about 3 secs into loop in get_comments()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import requests\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import csv\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set parameters for request\n",
    "\n",
    "subreddit = 'asianamerican'\n",
    "limit = 100\n",
    "timeframe = 'all' #hour, day, week, month, year, all\n",
    "listing = 'top' # controversial, best, hot, new, random, rising, top"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_reddit(): returns .json object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_reddit(subreddit,listing,limit,timeframe):\n",
    "    try:\n",
    "        base_url = f'https://www.reddit.com/r/{subreddit}/{listing}.json?limit={limit}&t={timeframe}'\n",
    "        request = requests.get(base_url, headers = {'User-agent': 'yourbot'})\n",
    "    except:\n",
    "        print('An Error Occured')\n",
    "    return request.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = get_reddit(subreddit, listing, limit, timeframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_post_titles(r):\n",
    "    '''\n",
    "    Get a List of post titles\n",
    "    '''\n",
    "    posts = []\n",
    "    for post in r['data']['children']:\n",
    "        x = post['data']['title']\n",
    "        posts.append(x)\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = get_post_titles(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n"
     ]
    }
   ],
   "source": [
    "print(len(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NBA All-Star Damian Lillard wears \"\"Stop Asian Hate\" shirt while sitting out tonight\\'s game', '“Fuck you! We will stop the Hate!” NBA star Baron Davis stands against anti-Asian racism.', 'Accurate', \"My friend's mother was one of the victims of Anti-Asian shooting that recently occurred. The gofundme already lays out their situation but she was a single mother working hard to support her kids through school and the pandemic. Any contributions would mean the world\", 'Megan Thee Stallion donates $50K to AAPI legal advocacy group after Atlanta spa shootings']\n"
     ]
    }
   ],
   "source": [
    "print(titles[0:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-88943241ff1d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# print keys/elements of a Reddit object (in this case, submission (t3))\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlist_red_objs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msearch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'children'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'data'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# important keys: (1) id (Reddit thing ID), (2) title, (3) ups (upvotes),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# (4) downs (downvotes), (5) score (not sure), (6) likes (not sure), (7) num_comments)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'search' is not defined"
     ]
    }
   ],
   "source": [
    "# print keys/elements of a Reddit object (in this case, submission (t3))\n",
    "list_red_objs = list(search['data']['children'][0]['data'].keys())\n",
    "\n",
    "# important keys: (1) id (Reddit thing ID), (2) title, (3) ups (upvotes), \n",
    "# (4) downs (downvotes), (5) score (not sure), (6) likes (not sure), (7) num_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>kind</th>\n",
       "      <th>data</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>all_awardings</th>\n",
       "      <td>t3</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>allow_live_comments</th>\n",
       "      <td>t3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approved_at_utc</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>approved_by</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>archived</th>\n",
       "      <td>t3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <td>t3</td>\n",
       "      <td>Shiggy_O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_flair_background_color</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_flair_css_class</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_flair_richtext</th>\n",
       "      <td>t3</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_flair_template_id</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_flair_text</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_flair_text_color</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_flair_type</th>\n",
       "      <td>t3</td>\n",
       "      <td>text</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_fullname</th>\n",
       "      <td>t3</td>\n",
       "      <td>t2_nu91ii0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_is_blocked</th>\n",
       "      <td>t3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_patreon_flair</th>\n",
       "      <td>t3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author_premium</th>\n",
       "      <td>t3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>awarders</th>\n",
       "      <td>t3</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banned_at_utc</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>banned_by</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can_gild</th>\n",
       "      <td>t3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>can_mod_post</th>\n",
       "      <td>t3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>category</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clicked</th>\n",
       "      <td>t3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>content_categories</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>contest_mode</th>\n",
       "      <td>t3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created</th>\n",
       "      <td>t3</td>\n",
       "      <td>1.61681e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>created_utc</th>\n",
       "      <td>t3</td>\n",
       "      <td>1.61681e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>discussion_type</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>distinguished</th>\n",
       "      <td>t3</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>domain</th>\n",
       "      <td>t3</td>\n",
       "      <td>i.redd.it</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>downs</th>\n",
       "      <td>t3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>edited</th>\n",
       "      <td>t3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gilded</th>\n",
       "      <td>t3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gildings</th>\n",
       "      <td>t3</td>\n",
       "      <td>{}</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hidden</th>\n",
       "      <td>t3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hide_score</th>\n",
       "      <td>t3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <td>t3</td>\n",
       "      <td>me5ef9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_created_from_ads_ui</th>\n",
       "      <td>t3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>is_crosspostable</th>\n",
       "      <td>t3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              kind         data\n",
       "all_awardings                   t3           []\n",
       "allow_live_comments             t3         True\n",
       "approved_at_utc                 t3         None\n",
       "approved_by                     t3         None\n",
       "archived                        t3         True\n",
       "author                          t3     Shiggy_O\n",
       "author_flair_background_color   t3         None\n",
       "author_flair_css_class          t3         None\n",
       "author_flair_richtext           t3           []\n",
       "author_flair_template_id        t3         None\n",
       "author_flair_text               t3         None\n",
       "author_flair_text_color         t3         None\n",
       "author_flair_type               t3         text\n",
       "author_fullname                 t3   t2_nu91ii0\n",
       "author_is_blocked               t3        False\n",
       "author_patreon_flair            t3        False\n",
       "author_premium                  t3        False\n",
       "awarders                        t3           []\n",
       "banned_at_utc                   t3         None\n",
       "banned_by                       t3         None\n",
       "can_gild                        t3        False\n",
       "can_mod_post                    t3        False\n",
       "category                        t3         None\n",
       "clicked                         t3        False\n",
       "content_categories              t3         None\n",
       "contest_mode                    t3        False\n",
       "created                         t3  1.61681e+09\n",
       "created_utc                     t3  1.61681e+09\n",
       "discussion_type                 t3         None\n",
       "distinguished                   t3         None\n",
       "domain                          t3    i.redd.it\n",
       "downs                           t3            0\n",
       "edited                          t3        False\n",
       "gilded                          t3            0\n",
       "gildings                        t3           {}\n",
       "hidden                          t3        False\n",
       "hide_score                      t3        False\n",
       "id                              t3       me5ef9\n",
       "is_created_from_ads_ui          t3        False\n",
       "is_crosspostable                t3        False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# What categories do I need from each post?\n",
    "## Comments\n",
    "## \n",
    "\n",
    "#print(r['data']['children'])\n",
    "dict_ = pd.DataFrame.from_dict(r['data']['children'][0])\n",
    "dict_[0:40]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get_search()\n",
    "- gets the .json file of a Reddit search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected request url\n",
    "#https://www.reddit.com/r/asianamerican/search/?q=affirmative%20action&restrict_sr=1&sort=top\n",
    "\n",
    "def get_search(subreddit,query,limit,timeframe,sort,restrict_sr):\n",
    "    try:\n",
    "        base_url = f'https://www.reddit.com/r/{subreddit}/search.json?q={query}&restrict_sr={restrict_sr}&limit={limit}&t={timeframe}&sort={sort}'\n",
    "        request = requests.get(base_url, headers = {'User-agent': 'yourbot'})\n",
    "    except:\n",
    "        print('An Error Occured')\n",
    "    return request.json()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get top 10 post (submission) IDs from Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_n_submission_info(r, n):\n",
    "    '''\n",
    "    Get a List of post titles\n",
    "    r: .json object\n",
    "    n: num of top posts\n",
    "    # important keys: (1) id (Reddit thing ID), (2) title, (3) ups (upvotes), \n",
    "    # (4) downs (downvotes), (5) score (not sure), (6) likes (not sure), (7) num_comments)\n",
    "\n",
    "    Returns: pandas Dataframe object\n",
    "    '''\n",
    "    # create 3 empty arrays of length n\n",
    "    id_arr = np.empty(n, dtype=\"S10\")\n",
    "    up_arr = np.empty(n)\n",
    "    down_arr = np.empty(n)\n",
    "    score_arr = np.empty(n)\n",
    "    likes_arr = np.empty(n)\n",
    "    num_com_arr = np.empty(n)\n",
    "    \n",
    "    for i, post in enumerate(r['data']['children']):\n",
    "        id_arr[i] = post['data']['id']\n",
    "        up_arr[i] = post['data']['ups']\n",
    "        down_arr[i] = post['data']['downs']\n",
    "        score_arr[i] = post['data']['score']\n",
    "        likes_arr[i] = post['data']['likes']\n",
    "        num_com_arr[i] = post['data']['num_comments']\n",
    "\n",
    "    # create Dataframe\n",
    "    df = pd.DataFrame({'id': id_arr, 'upvotes': up_arr, 'downvotes': down_arr, 'score': score_arr, 'likes': likes_arr, 'num_comments': num_com_arr})\n",
    "\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Driver file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_search() params\n",
    "sr = 'asianamerican'\n",
    "q = 'affirmative action'\n",
    "limit = 100\n",
    "timeframe = 'all'\n",
    "sort = 'top'\n",
    "restrict_sr = 1\n",
    "\n",
    "# variable for array of titles\n",
    "titles = None\n",
    "\n",
    "search = get_search(subreddit=sr,query=q, limit=limit, timeframe=timeframe, sort=sort, restrict_sr=restrict_sr)\n",
    "df = get_top_n_submission_info(search, limit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>upvotes</th>\n",
       "      <th>downvotes</th>\n",
       "      <th>score</th>\n",
       "      <th>likes</th>\n",
       "      <th>num_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'14m8mf4'</td>\n",
       "      <td>242.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>242.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>357.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'hqic5b'</td>\n",
       "      <td>223.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>223.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>114.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'9nk0do'</td>\n",
       "      <td>210.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>210.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>44.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'sejv5m'</td>\n",
       "      <td>149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'h9tuc2'</td>\n",
       "      <td>138.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>138.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>108.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>b'sbrca3'</td>\n",
       "      <td>133.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>133.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>224.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>b'cwk0vc'</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>136.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>b'8ajkwc'</td>\n",
       "      <td>123.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>b'8usex7'</td>\n",
       "      <td>120.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>b'rjy8ut'</td>\n",
       "      <td>109.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>109.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>b'7481yg'</td>\n",
       "      <td>95.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>116.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>b'5btr2j'</td>\n",
       "      <td>94.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>94.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>b'87ru7q'</td>\n",
       "      <td>81.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>81.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>b'pvb846'</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>b'jny9p4'</td>\n",
       "      <td>68.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>139.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>b'3oymmf'</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>b'6rolbg'</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>b'8uonyt'</td>\n",
       "      <td>53.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>36.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>b'sz1qyo'</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>b'9meo0b'</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>b'8vt7kt'</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>b'8rlr3y'</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>b'j7ybkv'</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>b'9mzffm'</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>b'jm4x1b'</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>27.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>b'b9rf6b'</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>b'ti11r7'</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>b'3w7268'</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>b'6ruvgx'</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>51.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>b'9ozm49'</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>219.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>b'9wwgwt'</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>b'967i7r'</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>b'6t02ts'</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>b'9z3ssz'</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>b'6r0tss'</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>59.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>b'5cudq1'</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>b'sbvysg'</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>b'6rjw6f'</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>b'3dmbpz'</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>b'62q795'</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>b'9s7sz1'</td>\n",
       "      <td>25.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>b'3e4d2v'</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>b'36jedc'</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>b'4kq3uy'</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>b'5i6idf'</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>58.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>b'dezvi6'</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>b'9kgf7i'</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>40.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>b'21a4zz'</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>b'9oq200'</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>b'6riosv'</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  upvotes  downvotes  score  likes  num_comments\n",
       "0   b'14m8mf4'    242.0        0.0  242.0    NaN         357.0\n",
       "1    b'hqic5b'    223.0        0.0  223.0    NaN         114.0\n",
       "2    b'9nk0do'    210.0        0.0  210.0    NaN          44.0\n",
       "3    b'sejv5m'    149.0        0.0  149.0    NaN          85.0\n",
       "4    b'h9tuc2'    138.0        0.0  138.0    NaN         108.0\n",
       "5    b'sbrca3'    133.0        0.0  133.0    NaN         224.0\n",
       "6    b'cwk0vc'    132.0        0.0  132.0    NaN         136.0\n",
       "7    b'8ajkwc'    123.0        0.0  123.0    NaN          32.0\n",
       "8    b'8usex7'    120.0        0.0  120.0    NaN          42.0\n",
       "9    b'rjy8ut'    109.0        0.0  109.0    NaN          39.0\n",
       "10   b'7481yg'     95.0        0.0   95.0    NaN         116.0\n",
       "11   b'5btr2j'     94.0        0.0   94.0    NaN          23.0\n",
       "12   b'87ru7q'     81.0        0.0   81.0    NaN          81.0\n",
       "13   b'pvb846'     78.0        0.0   78.0    NaN          30.0\n",
       "14   b'jny9p4'     68.0        0.0   68.0    NaN         139.0\n",
       "15   b'3oymmf'     63.0        0.0   63.0    NaN          65.0\n",
       "16   b'6rolbg'     56.0        0.0   56.0    NaN          42.0\n",
       "17   b'8uonyt'     53.0        0.0   53.0    NaN          36.0\n",
       "18   b'sz1qyo'     51.0        0.0   51.0    NaN          19.0\n",
       "19   b'9meo0b'     49.0        0.0   49.0    NaN          65.0\n",
       "20   b'8vt7kt'     44.0        0.0   44.0    NaN          30.0\n",
       "21   b'8rlr3y'     44.0        0.0   44.0    NaN          42.0\n",
       "22   b'j7ybkv'     41.0        0.0   41.0    NaN           3.0\n",
       "23   b'9mzffm'     36.0        0.0   36.0    NaN          75.0\n",
       "24   b'jm4x1b'     36.0        0.0   36.0    NaN          27.0\n",
       "25   b'b9rf6b'     35.0        0.0   35.0    NaN           6.0\n",
       "26   b'ti11r7'     35.0        0.0   35.0    NaN          66.0\n",
       "27   b'3w7268'     28.0        0.0   28.0    NaN           6.0\n",
       "28   b'6ruvgx'     32.0        0.0   32.0    NaN          51.0\n",
       "29   b'9ozm49'     28.0        0.0   28.0    NaN         219.0\n",
       "30   b'9wwgwt'     29.0        0.0   29.0    NaN           9.0\n",
       "31   b'967i7r'     27.0        0.0   27.0    NaN          58.0\n",
       "32   b'6t02ts'     28.0        0.0   28.0    NaN           4.0\n",
       "33   b'9z3ssz'     29.0        0.0   29.0    NaN          24.0\n",
       "34   b'6r0tss'     31.0        0.0   31.0    NaN          59.0\n",
       "35   b'5cudq1'     25.0        0.0   25.0    NaN           6.0\n",
       "36   b'sbvysg'     26.0        0.0   26.0    NaN           4.0\n",
       "37   b'6rjw6f'     26.0        0.0   26.0    NaN          11.0\n",
       "38   b'3dmbpz'     27.0        0.0   27.0    NaN           8.0\n",
       "39   b'62q795'     26.0        0.0   26.0    NaN           1.0\n",
       "40   b'9s7sz1'     25.0        0.0   25.0    NaN          14.0\n",
       "41   b'3e4d2v'     23.0        0.0   23.0    NaN           2.0\n",
       "42   b'36jedc'     23.0        0.0   23.0    NaN          60.0\n",
       "43   b'4kq3uy'     18.0        0.0   18.0    NaN           9.0\n",
       "44   b'5i6idf'     22.0        0.0   22.0    NaN          58.0\n",
       "45   b'dezvi6'     22.0        0.0   22.0    NaN          25.0\n",
       "46   b'9kgf7i'     20.0        0.0   20.0    NaN          40.0\n",
       "47   b'21a4zz'     23.0        0.0   23.0    NaN          38.0\n",
       "48   b'9oq200'     18.0        0.0   18.0    NaN           0.0\n",
       "49   b'6riosv'     18.0        0.0   18.0    NaN          14.0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['14m8mf4' 'hqic5b' '9nk0do' 'sejv5m' 'h9tuc2' 'sbrca3' 'cwk0vc' '8ajkwc'\n",
      " '8usex7' 'rjy8ut' '7481yg' '5btr2j' '87ru7q' 'pvb846' 'jny9p4' '3oymmf'\n",
      " '6rolbg' '8uonyt' 'sz1qyo' '9meo0b' '8vt7kt' '8rlr3y' 'j7ybkv' '9mzffm'\n",
      " 'jm4x1b' 'b9rf6b' 'ti11r7' '3w7268' '6ruvgx' '9ozm49' '9wwgwt' '967i7r'\n",
      " '6t02ts' '9z3ssz' '6r0tss' '5cudq1' 'sbvysg' '6rjw6f' '3dmbpz' '62q795'\n",
      " '9s7sz1' '3e4d2v' '36jedc' '4kq3uy' '5i6idf' 'dezvi6' '9kgf7i' '21a4zz'\n",
      " '9oq200' '6riosv' '23wexw' '3euiwo' '20ewl2' '31whah' '1yujng' '9rd4tx'\n",
      " '23ouhl' 'anfd61' 'hlnwtr' 'dskb09' 'ldzz0f' '6ra6ey' '105fx43' '9oovpa'\n",
      " 'jka8ii' '2n01k4' '1v63z3' '8a1j3p' '2rdduz' 'h107c4' '9ap203' '1juzmv'\n",
      " '6sqhhh' '3bkavj' 'sujd6e' '3rgzi3' '12e8uno' 'drhgp6' 'mauapi' '43eu4h'\n",
      " 'tuqh5o' '88rs2g' '266qsv' 'aulovs' '14v43k' '3ija6r' '2c8iu1' '3rkhqd'\n",
      " '4eb7qj' '4q20ib' '5cw7uu' '4lqzqq' '24hmx8' 'esbwk7' 'd6767e' '6ek03l'\n",
      " '1belws6' '4ziaf0' '789gct' 'bgj9bw']\n"
     ]
    }
   ],
   "source": [
    "# get column of t3 object submission IDs\n",
    "id_arr = df['id'].to_numpy()\n",
    "\n",
    "# decode strings from byte \n",
    "def decode_arr(x):\n",
    "    return x.decode('utf-8')\n",
    "\n",
    "vfunc = np.vectorize(decode_arr)\n",
    "id_arr_decoded = vfunc(id_arr)\n",
    "\n",
    "print(id_arr_decoded)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use id_arr to get comments of these submission id's."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get comments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using Reddit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "# Don't use below code - use PRAW instead\n",
    "def get_comments(sr, post_id, context, limit, showedits, showmedia, showmore, showtitle, theme, threaded, truncate, sort):\n",
    "    try:\n",
    "        base_url = f'https://www.reddit.com/r/{sr}/comments/{post_id}?context={context}&limit={limit}&showedits={showedits}&showmore={showmore}&showmedia={showmedia}&showtitle={showtitle}&sort={sort}&theme={theme}&threaded={threaded}&truncate={truncate}'\n",
    "        request = requests.get(base_url, headers = {'User_agent': 'yourbot'})\n",
    "        return request.json()\n",
    "    except:\n",
    "        print('An Error Occured')\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "sr = 'asianamerican'\n",
    "context = 5 # int: 0-8\n",
    "limit = 100\n",
    "showedits = False\n",
    "showmore = False\n",
    "showmedia = False\n",
    "showtitle = False\n",
    "sort = 'confidence' # one of (confidence, top, new, controversial, old, random, qa, live)\n",
    "theme = 'default'\n",
    "threaded = False\n",
    "truncate = 25\n",
    "post_id = 'sejv5m'\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An Error Occured\n"
     ]
    }
   ],
   "source": [
    "\n",
    "'''comments = get_comments(sr=sr,\n",
    "                        post_id=post_id,\n",
    "                        context=context,\n",
    "                        limit=limit,\n",
    "                        showedits=showedits,\n",
    "                        showmore=showmore,\n",
    "                        showtitle=showtitle,\n",
    "                        showmedia=showmedia,\n",
    "                        sort=sort,\n",
    "                        theme=theme,\n",
    "                        threaded=threaded,\n",
    "                        truncate=truncate)'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using PRAW Instead of Reddit API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import praw\n",
    "\n",
    "# need to take secret and password off of Github in the future\n",
    "\n",
    "reddit = praw.Reddit(\n",
    "    client_id=\"iaKUGuo77BwJYHElyAo1Jg\",\n",
    "    client_secret=\"19bSH4KJpPJB2WFeYhUe--jk4IKeHQ\",\n",
    "    password='Ehdwn1928K!',\n",
    "    user_agent=\"Comment Extraction u/dlehdwn\",\n",
    "    username='dlehdwn',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dlehdwn\n"
     ]
    }
   ],
   "source": [
    "print(reddit.user.me())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "#enable read-only mode\n",
    "#reddit.read_only = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(praw_obj, id_arr, filename):\n",
    "    '''\n",
    "    praw_obj: PRAW Reddit object\n",
    "    id_arr: array of Reddit t3 IDs\n",
    "    '''\n",
    "    # manual count of comments while traversing thru CommentTree to compare to actual number of comments\n",
    "    num_comments = 0\n",
    "\n",
    "    #open a file to write to\n",
    "    with open(filename, 'w', newline='', encoding=\"utf-8\") as f:\n",
    "\n",
    "        # writer\n",
    "        writer = csv.writer(f, delimiter=',', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "        for id in id_arr:\n",
    "            #print(f'id: {id}')\n",
    "            sub = praw_obj.submission(id)\n",
    "            \n",
    "            # get post data\n",
    "            time = datetime.datetime.fromtimestamp(sub.created)\n",
    "            post_text = sub.title + ' ' + sub.selftext\n",
    "\n",
    "            if sub.author is not None:\n",
    "                username = sub.author.name\n",
    "                #flair = sub.author_flair_text\n",
    "                writer.writerow([username, time, post_text])\n",
    "\n",
    "            else:\n",
    "                #print('comment.author is None')\n",
    "                #print(f'body: {body}\\n')\n",
    "                writer.writerow(['',time,post_text])    \n",
    "            \n",
    "            num_comments+=1\n",
    "\n",
    "\n",
    "            # get all comments\n",
    "            sub.comments.replace_more(limit=None, threshold=1) #threshold - min num of comments needed to traverse into \"More comments\" object\n",
    "            for comment in sub.comments.list():\n",
    "\n",
    "                # get comment text\n",
    "                body = comment.body\n",
    "\n",
    "                # strip comment of delimiter (|)\n",
    "                #body.replace('|','')\n",
    "                #body = body.strip() + '|'\n",
    "\n",
    "                # get username of comment author\n",
    "                if comment.author is not None:\n",
    "                    username = comment.author.name\n",
    "                    #flair = comment.author_flair_text\n",
    "                    time = datetime.datetime.fromtimestamp(comment.created)\n",
    "                    writer.writerow([username, time, body])\n",
    "                \n",
    "                else:\n",
    "                    #print('comment.author is None')\n",
    "                    #print(f'body: {body}\\n')\n",
    "                    writer.writerow(['','',body])\n",
    "\n",
    "                num_comments+=1\n",
    "\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    # return num of comments written\n",
    "    return num_comments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_comments_collected = get_comments(reddit, id_arr_decoded, 'top_100_post_comments_user_time_text.txt') #takes a min to run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3709.0\n",
      "3633\n"
     ]
    }
   ],
   "source": [
    "# num of actual total comments\n",
    "print(df['num_comments'].sum())\n",
    "\n",
    "# num of collected comments\n",
    "print(num_comments_collected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Num of comments collected\n",
    "- Num of collected posts and comments in top 100 posts: 3633\n",
    "- Num of actual total posts and comments in top 100 posts: 3709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = reddit.submission(\"14m8mf4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-06-29 10:54:44\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "\n",
    "# get datetime of post\n",
    "created = submission.created\n",
    "time = datetime.datetime.fromtimestamp(created)\n",
    "print(time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Megathread] Supreme Court Ruling on Affirmative Action\n",
      "Tungsten_\n",
      "None\n",
      "2023-06-29 10:54:44\n",
      "2023-06-29 10:54:44\n",
      "This is a consolidated thread for users to discuss today's supreme court decision on affirmative action at Harvard and UNC. Please, even in disagreement, be civil and kind.\n",
      "\n",
      "[NBC](https://www.nbcnews.com/politics/supreme-court/supreme-court-strikes-affirmative-action-programs-harvard-unc-rcna66770)\n",
      "\n",
      "[CNN](https://www.cnn.com/politics/live-news/supreme-court-decisions/index.html)\n",
      "\n",
      "[NYT](https://www.nytimes.com/live/2023/06/29/us/affirmative-action-supreme-court)\n",
      "\n",
      "[WaPo](https://www.washingtonpost.com/education/2023/06/29/supreme-court-student-loan-forgiveness-affirmative-action/)\n",
      "\n",
      "[Supreme Court Opinion](https://www.supremecourt.gov/opinions/22pdf/20-1199_hgdj.pdf)\n"
     ]
    }
   ],
   "source": [
    "if submission.author is not None:\n",
    "    username = submission.author.name\n",
    "    flair = submission.author_flair_text\n",
    "    time = datetime.datetime.fromtimestamp(submission.created)\n",
    "    time_utc = datetime.datetime.fromtimestamp(submission.created_utc) # created and created_utc return the same time\n",
    "    self_text = submission.selftext\n",
    "    title = submission.title\n",
    "\n",
    "print(title)\n",
    "print(username)\n",
    "print(flair)\n",
    "print(time)\n",
    "print(time_utc)\n",
    "print(self_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'submission' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-fc139244ebfa>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# print top level comments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mtop_level_comment\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msubmission\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcomments\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtop_level_comment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbody\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'submission' is not defined"
     ]
    }
   ],
   "source": [
    "# print top level comments\n",
    "for top_level_comment in submission.comments:\n",
    "    print(top_level_comment.body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thanks to everyone who engaged in insightful and respectful discourse about the news. \n",
      "\n",
      "This thread is now locked for comments.\n",
      "2023-06-30 11:33:11\n",
      "I would prefer using a process that takes into account poverty instead. \n",
      "\n",
      "The first generation of my family that came to America was *painfully* poor and everyone showed up with neither money nor education. They worked in kitchens and laundromats. Notice a lot of people in bigger reddit boards talking shit about the \"Chinese billionaire\" boogeyman (fearmongering like this also erases the less visible Asian races who came to America as refugees and reduces all Asians to a monolithic \"rich Asian stereotype\") and how this will only help them. The Chinese people I know were not coming to America with bags of cash.\n",
      "2023-06-29 11:16:15\n",
      "u/Tungsten_, Thanks for creating a section just to discuss this. When I read the news I immediately went searching for a forum where folks might have civil discourse on this topic.\n",
      "\n",
      "Just had a few comments/questions:\n",
      "\n",
      "1. Has anyone come across seemingly legitimate data sets on asians & college admission with respect to Affirmative Action (AA for short going forward)\n",
      "2. As an Asian (not born in the US but pretty much assimilated here for 35+ years), I am conflicted. Research results like this one show: [https://www.pewresearch.org/race-ethnicity/2023/06/08/asian-americans-hold-mixed-views-around-affirmative-action/](https://www.pewresearch.org/race-ethnicity/2023/06/08/asian-americans-hold-mixed-views-around-affirmative-action/) that something like 53% Asians think AA is a good thing, and yet when you scroll down and look at the question of \"Should colleges consider race/ethnicity in college admissions,\" the percentage of Asians that say yes are at 21%, no at 76%.\n",
      "\n",
      "I am part of the 76%.... and I'm conflicted. I know especially for the underserved, AA makes a significant impact in giving folks better chances at life which in turn translates to diversity in every facet of work, society, life in general, which I view is a good thing.\n",
      "\n",
      "But specifically regarding college admissions.. say for my own kids? (not college aged yet)  I would like to see more data on whether year 2000 and beyond AA in college admissions was harmful to Asians in general. In my own experience (anecdotal, totally not data science driven), I feel like AA in college admissions has hurt friends and family, in a reverse sort of sense.\n",
      "\n",
      "But for the sake of the underserved, I didn't want AA to go away. So I am deeply conflicted.\n",
      "\n",
      "Your thoughts?\n",
      "2023-06-29 11:09:47\n"
     ]
    }
   ],
   "source": [
    "submission.comments.replace_more(limit=None)\n",
    "for comment in submission.comments.list()[:3]:\n",
    "    print(comment.body)\n",
    "    print(datetime.datetime.fromtimestamp(comment.created))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4d9defa72c2715dab9f7f172572cd30a1ab1a2083462d32ef96aadb7c6e0c73b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
